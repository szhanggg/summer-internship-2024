{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d9db55-5b34-48c2-9ac2-6a4620003eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyhdf\n",
    "from pyhdf.SD import SD, SDC\n",
    "from pyhdf.HDF import *\n",
    "from pyhdf.VS import *\n",
    "from datetime import datetime, timezone\n",
    "from scipy import interpolate\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a6b62b-a348-4f9f-9bcf-12bbcd8c659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ===============================================\n",
    "def read_2b_cldclass_lidar(cs_file,latbin=None):\n",
    "## ===============================================\n",
    "  f_2b_cldclass_lidar=SD(cs_file, SDC.READ)\n",
    "  sds_obj=f_2b_cldclass_lidar.select('CloudLayerBase')\n",
    "  cs_clb =sds_obj.get()\n",
    "  sds_obj=f_2b_cldclass_lidar.select('CloudLayerTop')\n",
    "  cs_clt =sds_obj.get()\n",
    "\n",
    "  ## geolocation fields\n",
    "  sdc_2bcldclass_lidar=HDF(cs_file, SDC.READ)\n",
    "  vs_2bcldclass_lidar=sdc_2bcldclass_lidar.vstart()\n",
    "  cs_QC = np.squeeze(vs_2bcldclass_lidar.attach('Data_quality')[:])\n",
    "  Latitude = np.squeeze(vs_2bcldclass_lidar.attach('Latitude')[:])\n",
    "  Longitude = np.squeeze(vs_2bcldclass_lidar.attach('Longitude')[:])\n",
    "\n",
    "  ilat = np.squeeze(np.argwhere((Latitude >= latbin[0]) & (Latitude <= latbin[1])))\n",
    "  cs_clb = cs_clb[ilat,:]\n",
    "  cs_clt = cs_clt[ilat,:]\n",
    "  cs_QC = cs_QC[ilat]\n",
    "  Latitude = Latitude[ilat]\n",
    "  Longitude = Longitude[ilat]\n",
    "\n",
    "  return(cs_clb,cs_clt,cs_QC,Latitude,Longitude)\n",
    "\n",
    "## ===============================================\n",
    "def read_cs_ecmwf(aux_file,latbin=None):\n",
    "## ===============================================\n",
    "  f_ecmwf=SD(aux_file, SDC.READ)\n",
    "  sds_obj=f_ecmwf.select('Pressure')\n",
    "  Pressure =sds_obj.get()\n",
    "  sds_obj=f_ecmwf.select('Temperature')\n",
    "  Temperature =sds_obj.get()\n",
    "  sds_obj=f_ecmwf.select('Specific_humidity')\n",
    "  Specific_humidity =sds_obj.get()\n",
    "  #sds_obj=f_ecmwf.select('U_velocity')\n",
    "  #U_velocity =sds_obj.get()\n",
    "  #sds_obj=f_ecmwf.select('V_velocity')\n",
    "  #V_velocity =sds_obj.get()\n",
    "\n",
    "  ## geolocation fields\n",
    "  sdc_ecmwf=HDF(aux_file, SDC.READ)\n",
    "  vs_ecmwf=sdc_ecmwf.vstart()\n",
    "  EC_height = np.squeeze(vs_ecmwf.attach('EC_height')[:])\n",
    "  Profile_time = np.squeeze(vs_ecmwf.attach('Profile_time')[:])\n",
    "  UTC_start = np.squeeze(vs_ecmwf.attach('UTC_start')[:])\n",
    "  #TAI_start = np.squeeze(vs_ecmwf.attach('TAI_start')[:])\n",
    "  Latitude = np.squeeze(vs_ecmwf.attach('Latitude')[:])\n",
    "  Longitude = np.squeeze(vs_ecmwf.attach('Longitude')[:])\n",
    "  DEM_elevation = np.squeeze(vs_ecmwf.attach('DEM_elevation')[:])\n",
    "  Skin_temperature = np.squeeze(vs_ecmwf.attach('Skin_temperature')[:])\n",
    "  Surface_pressure = np.squeeze(vs_ecmwf.attach('Surface_pressure')[:])\n",
    "  Temperature_2m = np.squeeze(vs_ecmwf.attach('Temperature_2m')[:])\n",
    "  #Sea_surface_temperature = np.squeeze(vs_ecmwf.attach('Sea_surface_temperature')[:])\n",
    "  U10_velocity = np.squeeze(vs_ecmwf.attach('U10_velocity')[:])\n",
    "  V10_velocity = np.squeeze(vs_ecmwf.attach('V10_velocity')[:])\n",
    "\n",
    "\n",
    "  UTC_Time = UTC_start + Profile_time\n",
    "  UTC_Time = UTC_Time/60./60.\n",
    "  ilat = np.squeeze(np.argwhere((Latitude >= latbin[0]) & (Latitude <= latbin[1])))\n",
    "  Pressure = Pressure[ilat,:]\n",
    "  Temperature = Temperature[ilat,:]\n",
    "  Specific_humidity = Specific_humidity[ilat,:]\n",
    "  DEM_elevation = DEM_elevation[ilat]\n",
    "  Skin_temperature = Skin_temperature[ilat]\n",
    "  Temperature_2m = Temperature_2m[ilat]\n",
    "  U10_velocity = U10_velocity[ilat]\n",
    "  V10_velocity = V10_velocity[ilat]\n",
    "  UTC_Time = UTC_Time[ilat]\n",
    "\n",
    "\n",
    "  return(Pressure,DEM_elevation,Temperature,Specific_humidity,EC_height,Temperature_2m,U10_velocity,V10_velocity,UTC_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd221f8-9f59-4175-9a7d-a5ceb26cdd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory, prefix):\n",
    "    matching_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(prefix):\n",
    "            matching_files.append(os.path.join(directory, filename))\n",
    "    return matching_files\n",
    "\n",
    "def gather_files(YYYY, DDD, HH, ROOT):\n",
    "    ABI_ = {\n",
    "        \"ROOT_PATH\": None,\n",
    "\n",
    "        \"YYYY\": None,\n",
    "        \"DDD\": None,\n",
    "        \"HH\": None,\n",
    "\n",
    "        \"00\": [],\n",
    "        \"10\": [],\n",
    "        \"15\": [],\n",
    "        \"20\": [],\n",
    "        \"30\": [],\n",
    "        \"40\": [],\n",
    "        \"45\": [],\n",
    "        \"50\": [],\n",
    "\n",
    "        \"L200\": None,\n",
    "        \"L210\": None,\n",
    "        \"L220\": None,\n",
    "        \"L230\": None,\n",
    "        \"L240\": None,\n",
    "        \"L250\": None,\n",
    "\n",
    "        \"everyten\": False,\n",
    "    }\n",
    "\n",
    "    _ABI_PATH_ = ROOT + YYYY + \"/\" + DDD + \"/\" + HH\n",
    "\n",
    "    for filename in os.listdir(_ABI_PATH_):\n",
    "        if ABI_[\"ROOT_PATH\"] == None:\n",
    "            ABI_[\"ROOT_PATH\"] = _ABI_PATH_\n",
    "            ABI_[\"YYYY\"] = filename[27:31]\n",
    "            ABI_[\"DDD\"] = filename[31:34]\n",
    "            ABI_[\"HH\"] = filename[34:36]\n",
    "        MM = filename[36:38]\n",
    "        if MM == \"10\":\n",
    "            ABI_[\"everyten\"] = True\n",
    "        ABI_[f\"{MM}\"].append(filename)\n",
    "    \n",
    "    return ABI_\n",
    "\n",
    "def get_L1B_L2(abipaths, l2path, YYYY, DDD, HH, ROOT):\n",
    "\n",
    "    # ASSERT ALL ABI CHANNELS PRESENT !!!!!!!!!!!!!!!!!!!!\n",
    "    if len(abipaths) != 16:\n",
    "        raise ImportError(\"This hour is bad\")\n",
    "    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "    # LOAD EACH ABI CHANNEL IMAGE\n",
    "    CHANNELS = []\n",
    "    # ROOT = \"/css/geostationary/BackStage/GOES-16-ABI-L1B-FULLD/\"\n",
    "\n",
    "    for file in abipaths:\n",
    "        L1B = np.array(nc.Dataset(ROOT + \"/\" + YYYY + \"/\" + DDD + \"/\" + HH + \"/\" + file, 'r')[\"Rad\"])\n",
    "        CHANNEL = int(file[19:21])\n",
    "        CHANNELS.append((L1B, CHANNEL))\n",
    "\n",
    "    # SORT CHANNELS\n",
    "    CHANNELS.sort(key=lambda x: x[1])\n",
    "    CHANNELS = [C[0] for C in CHANNELS]\n",
    "\n",
    "    T = []\n",
    "    #RESIZE ALL CHANNELS TO SAME SIZE\n",
    "    for C in CHANNELS:\n",
    "        S = C.shape[0] // 5424\n",
    "        if S == 1:\n",
    "            C = np.repeat(C, 2, axis=0)\n",
    "            C = np.repeat(C, 2, axis=1)\n",
    "        if S == 4:\n",
    "            C = C[::2, ::2]\n",
    "        T.append(C)\n",
    "\n",
    "    CHANNELS = T\n",
    "\n",
    "    # STACK ABI CHANNELS INTO SINGLE IMAGE\n",
    "    ABI = np.stack(CHANNELS, axis=2)\n",
    "\n",
    "    return ABI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244d21f0-147c-4421-962f-ec4e0198ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUND_SIZE = 2000\n",
    "LENGTH = 10848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfb035a-446d-4b72-8b12-2df854efb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN ABI_EAST in order to find the latitude and longitude of each file\n",
    "f = nc.Dataset(\"../ABI_EAST_GEO_TOPO_LOMSK.nc\")\n",
    "abiLong = np.array(f['Longitude'])\n",
    "abiLat = np.array(f['Latitude'])\n",
    "\n",
    "# Get the latitude and longitude boundaries within the bounded region\n",
    "\n",
    "abiLongB = abiLong[BOUND_SIZE:LENGTH-BOUND_SIZE, BOUND_SIZE:LENGTH-BOUND_SIZE]\n",
    "abiLatB = abiLat[BOUND_SIZE:LENGTH-BOUND_SIZE, BOUND_SIZE:LENGTH-BOUND_SIZE]\n",
    "abiLongB[abiLongB == -999] = 10\n",
    "abiLatB[abiLatB == -999] = 10\n",
    "longMin = abiLongB.min()\n",
    "longMax = abiLongB.max()\n",
    "latMin = abiLatB.min()\n",
    "latMax = abiLatB.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6adf036a-036a-4267-a246-9f8a5a1291ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if they loaded correctly\n",
    "# abiLongG = abiLong.copy()\n",
    "# abiLatG = abiLat.copy()\n",
    "\n",
    "# abiLongG = abiLongG.flatten()\n",
    "# abiLatG = abiLatG.flatten()\n",
    "\n",
    "# mask = (abiLongG != -999) & (abiLatG != -999)\n",
    "# abiLongG = abiLongG[mask]\n",
    "# abiLatG = abiLatG[mask]\n",
    "\n",
    "# print(abiLongG.shape)\n",
    "\n",
    "# abiLongG = abiLongG[::1000]\n",
    "# abiLatG = abiLatG[::1000]\n",
    "\n",
    "# plt.scatter(abiLongG, abiLatG, c='blue', marker='o')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# im0 = axes[0].imshow(abiLongG)\n",
    "# im1 = axes[1].imshow(abiLatG)\n",
    "# # axes[0].axis('off')\n",
    "# # axes[1].axis('off')\n",
    "# axes[0].set_title(\"Longitude\")\n",
    "# axes[1].set_title(\"Latitude\")\n",
    "# plt.colorbar(im0, ax=axes[0])\n",
    "# plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# TEST FOOTPRINT SIZE\n",
    "# for i in np.arange(5000,5100):\n",
    "#   coords_1 = (abiLat[i,5000],abiLong[i,5000])\n",
    "#   coords_2 = (abiLat[i+1,5000],abiLong[i+1,5000])\n",
    " \n",
    "#   dis = geodesic(coords_1,coords_2).km\n",
    "#   print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccba55a-6116-4906-ab58-0886d42ed462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store already parsed files for more efficiency\n",
    "\n",
    "GATHERED_ABI_FILES = {}\n",
    "COLLECTED_ABI_DATA = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c95b76b-59f6-43d4-950a-0c4ba4491023",
   "metadata": {},
   "outputs": [],
   "source": [
    "latSlice = abiLat[:, 5424]\n",
    "latSlice = latSlice[18:-18]\n",
    "longSlice = abiLong[5424, :]\n",
    "longSlice = longSlice[18:-18]\n",
    "latSlice = latSlice[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51bb2230-d9a8-4fe8-9ea8-ecf6a51bde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpArray(a):\n",
    "    N = len(a)\n",
    "    M = len(a[0])\n",
    "    a_interp = np.zeros((N, 40))\n",
    "\n",
    "    for i in range(N):\n",
    "        f = interpolate.interp1d(np.linspace(0,1,M), a[i], kind='linear')\n",
    "        a_interp[i] = f(np.linspace(0, 1, 40))\n",
    "\n",
    "    return a_interp\n",
    "\n",
    "def processTime(t, yy, ddn, lat, lon, ABI_ROOT):\n",
    "    if np.floor(t) < 19:\n",
    "        raise ValueError(\"Times must be between 19-23\")\n",
    "\n",
    "    if lat < latMin or lat > latMax or lon < longMin or lon > longMax:\n",
    "        raise ValueError(\"Latitude and Longitude are not correctly bounded\")\n",
    "    # # Find the proper index using Manhattan distance\n",
    "    # distances = np.abs(abiLat - lat) + np.abs(abiLong - lon)\n",
    "\n",
    "    # # distances = distances[BOUND_SIZE:LENGTH-BOUND_SIZE,BOUND_SIZE:LENGTH-BOUND_SIZE]\n",
    "    \n",
    "    # # Find minimum value in distances array\n",
    "    # coords = np.unravel_index(distances.argmin(), distances.shape)\n",
    "    # # coords = np.array(coords) + BOUND_SIZE\n",
    "    # # if coords[0] < BOUND_SIZE or coords[1] < BOUND_SIZE or coords[1] > LENGTH-BOUND_SIZE or coords[0] > LENGTH-BOUND_SIZE:\n",
    "    # #     raise ImportError(\"Bad latitude and longitude\")\n",
    "    # MORE OPTIMIZED: Find the proper index using Binary Search\n",
    "\n",
    "    AREA_SIZE = 1000\n",
    "\n",
    "    lati = len(latSlice) - np.searchsorted(latSlice, lat) + 17\n",
    "    loni = np.searchsorted(longSlice, lon) + 18\n",
    "    \n",
    "    distances = np.abs(abiLat[lati-AREA_SIZE:lati+AREA_SIZE, loni-AREA_SIZE:loni+AREA_SIZE] - lat) + np.abs(abiLong[lati-AREA_SIZE:lati+AREA_SIZE, loni-AREA_SIZE:loni+AREA_SIZE] - lon)\n",
    "    coords = np.array(np.unravel_index(distances.argmin(), distances.shape))\n",
    "    if coords[0] == 0 or coords[1] == 0 or coords[1] == 2*AREA_SIZE-1 or coords[0] == 2*AREA_SIZE - 1:\n",
    "        print(\"FALLBACK\")\n",
    "        distances = np.abs(abiLat - lat) + np.abs(abiLong - lon)\n",
    "        coords = np.unravel_index(distances.argmin(), distances.shape)\n",
    "    else:\n",
    "        coords[0] += lati - AREA_SIZE\n",
    "        coords[1] += loni - AREA_SIZE\n",
    "\n",
    "    if coords[0] < BOUND_SIZE or coords[1] < BOUND_SIZE or coords[1] > LENGTH-BOUND_SIZE or coords[0] > LENGTH-BOUND_SIZE:\n",
    "        raise ValueError(\"Bad latitude and longitude\")\n",
    "        \n",
    "    # print(coords[0] - ncoords[0], coords[1] - ncoords[1])\n",
    "\n",
    "    hour = np.floor(t).astype(int)\n",
    "\n",
    "    # Gather the ABI_FILE\n",
    "    DATA = GATHERED_ABI_FILES.get(f'{yy}-{ddn}-{hour}')\n",
    "    if DATA is None:\n",
    "        DATA = gather_files(str(yy), str(ddn), str(hour), ABI_ROOT)\n",
    "        GATHERED_ABI_FILES[f'{yy}-{ddn}-{hour}'] = DATA\n",
    "\n",
    "    # Find the closest minute\n",
    "    if DATA[\"everyten\"]:\n",
    "        minutes = np.round((t - np.floor(t)) * 6).astype(int) * 10\n",
    "    else:\n",
    "        minutes = np.round((t - np.floor(t)) * 4).astype(int) * 15\n",
    "\n",
    "    # If minutes is closer to the next hour, shift the hour forward by one, unless that would cause a day shift\n",
    "    if minutes == 60:\n",
    "        if hour != 23:\n",
    "            hour += 1\n",
    "            minutes = 0\n",
    "        else:\n",
    "            if DATA[\"everyten\"]:\n",
    "                minutes = 50\n",
    "            else:\n",
    "                minutes = 45\n",
    "\n",
    "    minutes = str(minutes)\n",
    "    if minutes == \"0\":\n",
    "        minutes =\"00\"\n",
    "\n",
    "    ABI = COLLECTED_ABI_DATA.get(f'{yy}-{ddn}-{hour}-{minutes}')\n",
    "    if ABI is None:\n",
    "        ABI = get_L1B_L2(DATA[minutes], DATA[\"L200\"], DATA[\"YYYY\"], DATA[\"DDD\"], DATA[\"HH\"], ABI_ROOT)\n",
    "        COLLECTED_ABI_DATA[f'{yy}-{ddn}-{hour}-{minutes}'] = ABI\n",
    "\n",
    "    chip = ABI[coords[0]-64:coords[0]+64, coords[1]-64:coords[1]+64, :]\n",
    "\n",
    "    return chip, coords\n",
    "\n",
    "translation = [1, 2, 0, 4, 5, 6, 3, 8, 9, 10, 11, 13, 14, 15]\n",
    "    \n",
    "def processFile(yy, ddn, orbit, latb):\n",
    "    cloudsatpath = '/explore/nobackup/people/jgong/cloudsat/'\n",
    "    #cloudsatpath = '/discover/nobackup/jgong/cloudsat/'\n",
    "    cs_file = glob.glob(cloudsatpath+'2B-CLDCLASS-LIDAR/'+yy+'/'+ddn+'/'+yy+ddn+'*'+orbit+'*2B-CLDCLASS-LIDAR*'+'P1_R05*.hdf')\n",
    "    aux_file = glob.glob(cloudsatpath+'ECMWF-AUX/'+yy+'/'+ddn+'/'+yy+ddn+'*'+orbit+'*ECMWF-AUX*'+'P1_R05*.hdf')\n",
    "\n",
    "    if len(cs_file) == 0 or len(aux_file) == 0:\n",
    "        print(\"NO CS OR AUX\")\n",
    "        return\n",
    "\n",
    "    [Pressure,DEM_elevation,Temperature,Specific_humidity,EC_height,Temperature_2m,\\\n",
    "        U10_velocity,V10_velocity,UTC_Time] = read_cs_ecmwf(aux_file[0],latbin=latb)\n",
    "\n",
    "    ##========== read 2b-cldclass-lidar ================================\n",
    "    [cs_clb,cs_clt,cs_QC,Latitude,Longitude] = read_2b_cldclass_lidar(cs_file[0],latbin=latb)\n",
    "    \n",
    "    Pressure = interpArray(Pressure)\n",
    "    Temperature = interpArray(Temperature)\n",
    "    Specific_humidity = interpArray(Specific_humidity)\n",
    "    \n",
    "    N = len(cs_clb)\n",
    "\n",
    "    cs_clb_2 = np.floor(2 * cs_clb).astype(int)\n",
    "    cs_clt_2 = np.floor(2 * cs_clt).astype(int)\n",
    "    \n",
    "    newRescaled = np.zeros((N, 40)).astype(int)\n",
    "    for i in range(N):\n",
    "        for j in range(10):\n",
    "            if cs_clb[i, j] == -99:\n",
    "                break\n",
    "            newRescaled[i, cs_clb_2[i, j]:cs_clt_2[i, j]+1] = 1\n",
    "\n",
    "    # Find corresponding ABI file to the UTC_Time\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    while i < N:\n",
    "        try:\n",
    "            chip, coords = processTime(UTC_Time[i], yy, ddn, Latitude[i], Longitude[i], '/explore/nobackup/people/szhang16/ABI-L1b-RadF/')\n",
    "        except ValueError:\n",
    "            i += 20\n",
    "            continue\n",
    "        except ImportError:\n",
    "            print(\"MISSING ABI DATA\")\n",
    "            print(yy, ddn, UTC_Time[i])\n",
    "            i += 90\n",
    "            continue\n",
    "            \n",
    "        # dRange = np.arange(i-45, i+46)\n",
    "        # Reverse the CloudSAT Data\n",
    "        dRange = np.arange(i+46, i-45, -1)\n",
    "        aux_data = {\n",
    "            \"Pressure\": Pressure[dRange],\n",
    "            \"DEM_elevation\": DEM_elevation[dRange],\n",
    "            \"Temperature\": Temperature[dRange],\n",
    "            \"Specific_humidity\": Specific_humidity[dRange],\n",
    "            \"Temperature_2m\": Temperature_2m[dRange],\n",
    "            \"U10_velocity\": U10_velocity[dRange],\n",
    "            \"V10_velocity\": V10_velocity[dRange],\n",
    "            \"UTC_Time\": UTC_Time[dRange],\n",
    "            \"Latitude\": Latitude[dRange],\n",
    "            \"Longitude\": Longitude[dRange],\n",
    "            \"Cloud_mask\": newRescaled[dRange],\n",
    "        }\n",
    "\n",
    "        fileName = f'{yy}-{ddn}-{orbit}_{coords[0]}-{coords[1]}'\n",
    "\n",
    "        chip = chip[..., translation]\n",
    "\n",
    "        np.savez('/explore/nobackup/people/szhang16/abiCloudSATChips/' + fileName, chip=chip, data=aux_data)\n",
    "        print(fileName)\n",
    "\n",
    "        i += 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca22c8-1867-4a20-9373-2ad26c4c5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING FILE 2019 360 72784\n",
      "2019-360-72784_8835-4113\n",
      "2019-360-72784_8799-4095\n",
      "2019-360-72784_8762-4077\n",
      "2019-360-72784_8726-4060\n",
      "2019-360-72784_8689-4042\n",
      "2019-360-72784_8652-4024\n",
      "2019-360-72784_8614-4006\n",
      "2019-360-72784_8577-3989\n",
      "2019-360-72784_8539-3971\n",
      "2019-360-72784_8501-3954\n",
      "2019-360-72784_8462-3936\n",
      "2019-360-72784_8424-3919\n",
      "2019-360-72784_8385-3902\n",
      "2019-360-72784_8346-3884\n",
      "2019-360-72784_8306-3867\n",
      "2019-360-72784_8267-3850\n",
      "2019-360-72784_8227-3833\n",
      "2019-360-72784_8187-3816\n",
      "2019-360-72784_8146-3799\n",
      "2019-360-72784_8106-3782\n",
      "2019-360-72784_8065-3765\n",
      "2019-360-72784_8024-3749\n",
      "2019-360-72784_7983-3732\n",
      "2019-360-72784_7941-3716\n",
      "2019-360-72784_7899-3699\n",
      "2019-360-72784_7858-3683\n",
      "2019-360-72784_7815-3666\n",
      "2019-360-72784_7773-3650\n",
      "2019-360-72784_7730-3634\n",
      "2019-360-72784_7688-3618\n",
      "2019-360-72784_7645-3602\n",
      "2019-360-72784_7602-3587\n",
      "2019-360-72784_7559-3571\n",
      "2019-360-72784_7515-3555\n",
      "2019-360-72784_7471-3540\n",
      "2019-360-72784_7427-3524\n",
      "2019-360-72784_7383-3509\n",
      "2019-360-72784_7339-3494\n",
      "2019-360-72784_7295-3479\n",
      "2019-360-72784_7251-3464\n",
      "2019-360-72784_7206-3449\n",
      "2019-360-72784_7161-3434\n",
      "2019-360-72784_7116-3420\n",
      "2019-360-72784_7071-3405\n",
      "2019-360-72784_7026-3391\n",
      "2019-360-72784_6981-3377\n",
      "2019-360-72784_6935-3363\n",
      "2019-360-72784_6889-3349\n",
      "2019-360-72784_6844-3335\n",
      "2019-360-72784_6798-3321\n",
      "2019-360-72784_6752-3308\n",
      "2019-360-72784_6706-3294\n",
      "2019-360-72784_6659-3281\n",
      "2019-360-72784_6613-3268\n",
      "2019-360-72784_6567-3255\n",
      "2019-360-72784_6520-3242\n",
      "2019-360-72784_6473-3229\n",
      "2019-360-72784_6427-3217\n",
      "2019-360-72784_6380-3204\n",
      "2019-360-72784_6333-3192\n",
      "2019-360-72784_6286-3180\n",
      "2019-360-72784_6239-3168\n",
      "2019-360-72784_6192-3156\n",
      "2019-360-72784_6145-3145\n",
      "2019-360-72784_6098-3133\n",
      "2019-360-72784_6051-3122\n",
      "2019-360-72784_6003-3111\n",
      "2019-360-72784_5956-3099\n",
      "2019-360-72784_5909-3089\n",
      "2019-360-72784_5861-3078\n",
      "2019-360-72784_5814-3067\n",
      "2019-360-72784_5766-3057\n",
      "2019-360-72784_5719-3047\n",
      "2019-360-72784_5671-3037\n",
      "2019-360-72784_5624-3027\n",
      "2019-360-72784_5576-3017\n",
      "2019-360-72784_5529-3008\n",
      "2019-360-72784_5481-2998\n",
      "2019-360-72784_5434-2989\n",
      "2019-360-72784_5386-2980\n",
      "2019-360-72784_5339-2971\n",
      "2019-360-72784_5291-2963\n",
      "2019-360-72784_5244-2954\n",
      "2019-360-72784_5196-2946\n",
      "2019-360-72784_5149-2938\n",
      "2019-360-72784_5102-2930\n",
      "2019-360-72784_5054-2922\n",
      "2019-360-72784_5007-2915\n",
      "2019-360-72784_4960-2907\n",
      "2019-360-72784_4913-2900\n",
      "2019-360-72784_4865-2893\n",
      "2019-360-72784_4818-2886\n",
      "2019-360-72784_4771-2880\n",
      "2019-360-72784_4724-2873\n",
      "2019-360-72784_4678-2867\n",
      "2019-360-72784_4631-2861\n",
      "2019-360-72784_4584-2855\n",
      "2019-360-72784_4537-2850\n",
      "2019-360-72784_4491-2844\n",
      "2019-360-72784_4444-2839\n",
      "2019-360-72784_4398-2834\n",
      "2019-360-72784_4352-2829\n",
      "2019-360-72784_4306-2824\n",
      "2019-360-72784_4260-2820\n",
      "2019-360-72784_4214-2816\n",
      "2019-360-72784_4168-2811\n",
      "2019-360-72784_4122-2808\n",
      "2019-360-72784_4077-2804\n",
      "2019-360-72784_4032-2800\n",
      "2019-360-72784_3986-2797\n",
      "2019-360-72784_3941-2794\n",
      "2019-360-72784_3896-2791\n",
      "2019-360-72784_3851-2788\n",
      "2019-360-72784_3807-2786\n",
      "2019-360-72784_3762-2784\n",
      "2019-360-72784_3718-2781\n",
      "2019-360-72784_3673-2780\n",
      "2019-360-72784_3629-2778\n",
      "2019-360-72784_3586-2776\n",
      "2019-360-72784_3542-2775\n",
      "2019-360-72784_3498-2774\n",
      "2019-360-72784_3455-2773\n",
      "2019-360-72784_3412-2772\n",
      "2019-360-72784_3369-2772\n",
      "2019-360-72784_3326-2772\n",
      "2019-360-72784_3283-2772\n",
      "2019-360-72784_3241-2772\n",
      "2019-360-72784_3199-2772\n",
      "2019-360-72784_3157-2772\n",
      "2019-360-72784_3115-2773\n",
      "2019-360-72784_3073-2774\n",
      "2019-360-72784_3032-2775\n",
      "2019-360-72784_2991-2776\n",
      "2019-360-72784_2950-2778\n",
      "2019-360-72784_2909-2780\n",
      "2019-360-72784_2869-2781\n",
      "2019-360-72784_2828-2784\n",
      "2019-360-72784_2788-2786\n",
      "2019-360-72784_2749-2788\n",
      "2019-360-72784_2709-2791\n",
      "2019-360-72784_2670-2794\n",
      "2019-360-72784_2631-2797\n",
      "2019-360-72784_2592-2800\n",
      "2019-360-72784_2553-2804\n",
      "2019-360-72784_2515-2807\n",
      "2019-360-72784_2477-2811\n",
      "2019-360-72784_2439-2815\n",
      "2019-360-72784_2401-2820\n",
      "2019-360-72784_2364-2824\n",
      "2019-360-72784_2327-2829\n",
      "2019-360-72784_2290-2834\n",
      "2019-360-72784_2253-2839\n",
      "2019-360-72784_2217-2844\n",
      "2019-360-72784_2181-2849\n",
      "2019-360-72784_2145-2855\n",
      "2019-360-72784_2110-2861\n",
      "2019-360-72784_2075-2866\n",
      "2019-360-72784_2040-2873\n",
      "2019-360-72784_2005-2879\n",
      "PROCESSING FILE 2019 360 72785\n",
      "2019-360-72785_8837-2350\n",
      "2019-360-72785_8801-2324\n",
      "2019-360-72785_8766-2299\n",
      "2019-360-72785_8730-2274\n",
      "2019-360-72785_8694-2248\n",
      "2019-360-72785_8657-2223\n",
      "2019-360-72785_8621-2199\n",
      "2019-360-72785_8584-2174\n",
      "2019-360-72785_8548-2150\n",
      "2019-360-72785_8511-2126\n",
      "2019-360-72785_8473-2102\n",
      "2019-360-72785_8435-2078\n",
      "2019-360-72785_8397-2054\n",
      "2019-360-72785_8359-2031\n",
      "2019-360-72785_8321-2008\n",
      "PROCESSING FILE 2019 360 72786\n",
      "PROCESSING FILE 2019 310 72054\n"
     ]
    }
   ],
   "source": [
    "#=================================\n",
    "#    MAIN\n",
    "#=================================\n",
    "# yy = '2019'\n",
    "# ddn = '045'; orbit = '68181'\n",
    "\n",
    "# processFile(yy, ddn, orbit, (latMin, latMax))\n",
    "\n",
    "# for filename in os.listdir('/explore/nobackup/people/jgong/cloudsat/2B-CLDCLASS-LIDAR/2019/285'):\n",
    "#     if filename.endswith('.hdf'):\n",
    "#         if int(filename[7:9]) > 18:\n",
    "#             print(filename)\n",
    "#             processFile(\"2019\", \"285\", filename[14:19], (latMin, latMax))\n",
    "\n",
    "ROOT_DIR = '/explore/nobackup/people/jgong/cloudsat/2B-CLDCLASS-LIDAR'\n",
    "\n",
    "for year in os.listdir(ROOT_DIR):\n",
    "    if year == \"2018\":\n",
    "        continue\n",
    "    for day in os.listdir(ROOT_DIR + '/' + year):\n",
    "        GATHERED_ABI_FILES = {}\n",
    "        COLLECTED_ABI_DATA = {}\n",
    "        for file in os.listdir(ROOT_DIR + '/' + year + '/' + day):\n",
    "            if file.endswith('hdf'):\n",
    "                orbit = file[14:19]\n",
    "                if int(file[7:9]) > 18:\n",
    "                    print(f\"PROCESSING FILE {year} {day} {orbit}\")\n",
    "                    processFile(year, day, orbit, (latMin, latMax))\n",
    "\n",
    "# for i in np.arange(10):\n",
    "#   tmp=np.squeeze(cs_clt[:,i])\n",
    "#   ind=np.argwhere(tmp>0)\n",
    "#   print(len(ind),len(tmp))\n",
    "\n",
    "#---- implementing the 40-level cloud mask processing code from ----\n",
    "#---- https://colab.research.google.com/drive/1cIsSLS5ht8PXQ8bAbJpboAIxrnanwupu -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba2407-2a24-4fe7-9dce-45ae555e6b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-pytorch]",
   "language": "python",
   "name": "conda-env-ilab-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
